---
title: "Readings in Database Systems 3. Методы, которые должен знать каждый"
date: 2020-07-23T10:24:43+03:00
summary: "В этой главе мы представляем первичные и почти первичные источники для
нескольких наиболее важных концепций проектирования систем баз данных:
планирование запросов, контроль параллелизма, восстановление базы данных и
распределённость. Идеи в этой главе настолько фундаментальны для современных
систем баз данных, что их содержит почти каждая зрелая БД. Три статьи в этой
главе - это, безусловно, канонические ссылки на соответствующие темы. Более того,
в отличие от предыдущей главы, эта глава фокусируется на широко применяемых
методах и алгоритмах, а не на целых системах."
categories:
- readings in database systems
- red book
- query optimization
- concurrency control
- database recovery
- distribution
draft: true
---

# 3. Методы, которые должен знать каждый

> Избранные статьи:
> 
> - Patricia G. Selinger, Morton M. Astrahan, Donald D. Chamberlin, Raymond A. Lorie,
>   Thomas G. Price. Access path selection in a relational database management system.
>   SIGMOD, 1979.
> - C. Mohan, Donald J. Haderle, Bruce G. Lindsay, Hamid Pirahesh, Peter M. Schwarz.
>   ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and
>   Partial Rollbacks Using Write-Ahead Logging. ACM Transactions on Database Systems,
>   17(1), 1992, 94-162.
> - Jim Gray, Raymond A. Lorie, Gianfranco R. Putzolu, Irving L. Traiger.
>   Granularity of Locks and Degrees of Consistency in a Shared Data Base.
>   IBM, September, 1975.
> - Rakesh Agrawal, Michael J. Carey, Miron Livny. Concurrency Control
>   Performance Modeling: Alternatives and Implications. ACM Transactions on
>   Database Systems, 12(4), 1987, 609-654.
> - C. Mohan, Bruce G. Lindsay, Ron Obermarck. Transaction Management in the R\*
>   Distributed Database Management System. ACM Transactions on Database Systems,
>   11(4), 1986, 378-396

{{< param Summary >}}

## Оптимизация запросов

Оптимизация запросов важна в архитектуре реляционных баз данных, поскольку она
является основой для обеспечения возможности обработки запросов, независимой от
данных. Основополагающий документ Селинджера и др. по System R обеспечивает
практическую оптимизацию запросов, разбивая проблему на три отдельных подзадачи:
оценка стоимости, реляционные эквивалентности, определяющие пространство поиска, и
поиск на основе затрат.

Оптимизатор предоставляет оценку стоимости выполнения каждого компонента
запроса, измеряемую в терминах затрат ввода-вывода и ЦП. Для этого оптимизатор
полагается как на предварительно вычисленную статистику по содержимому каждой
таблицы (хранящейся в системном каталоге), так и на набор эвристик для
определения кардинальности (размера) результата запроса (например, на основе
вычисленной селективности предикатов). В качестве упражнения рассмотрим эти
эвристики подробно: когда они осмыслены, а когда - нет? Как они могут быть
улучшены?

Используя эти оценки затрат, оптимизатор использует алгоритм динамического
программирования для построения плана запроса. Оптимизатор определяет набор
физических операторов, которые реализуют данный логический оператор (например,
поиск кортежа с использованием полного сканирования сегмента или с индексом).
Используя этот набор, оптимизатор итеративно создает «левое-глубокое» дерево
операторов, которое, в свою очередь, использует эвристику затрат, чтобы
минимизировать общий объем предполагаемой работы, требуемой для запуска
операторов, с учетом «интересных заказов», требуемых вышестоящими потребителями.
Это позволяет избежать необходимости учитывать все возможные упорядочения
операторов, но все еще имеет экспоненциальный размер плана; как мы увидим в
главе 7, современные оптимизаторы запросов по-прежнему борются с крупными
планами (например, с множественными объединениями). Кроме того, хотя оптимизатор
Selinger и соавторов выполняет компиляцию заранее, другие ранние системы, такие как
Ingres [^150], интерпретировали план запроса фактически, по принципу: кортеж за
кортежем.

Как и почти все оптимизаторы запросов, оптимизатор Selinger и соавторов
на самом деле не «оптимален» - нет никакой гарантии, что план,
который выберет оптимизатор, будет самым быстрым или самым дешевым. Реляционный
оптимизатор ближе по духу к оптимизации кода в современных языковых компиляторах
(т.е. будет выполняться поиск с максимальными усилиями), а не математическим
процедурам оптимизации (т. е. найдет лучшее решение). Однако многие современные
реляционные движки используют базовую методологию из данной статьи, включая
использование бинарных операторов и оценку стоимости.

## Управление параллелизмом

В нашей первой статье о транзакциях от Грея и др. представлены две классические
идеи: многоуровневая блокировка и несколько блокировочных режимов. Эта статья,
фактически, читается как две отдельных статьи.

Во-первых, в статье представлена концепция многоуровневой блокировки. Проблема
здесь проста: при наличии базы данных с иерархической структурой, как мы должны
выполнять взаимное исключение? Когда мы должны зафиксировать грубую
гранулярность (например, всю базу данных) по сравнению с более тонкой
гранулярностью (например, одна запись), и как мы можем поддерживать
одновременный доступ к различным частям иерархии одновременно? Хотя
иерархическая структура Грея и др. (cостоящая из баз данных, областей, файлов,
индексов и записей) немного отличается от современных систем баз данных, все
системы блокировки баз данных, кроме самых элементарных, сегодня адаптируют
предложения Грея и соавторов.

Во-вторых, в статье развивается концепция множественных степеней изоляции. Как
Грей и авторы напоминают нам, что цель контроля параллелизма состоит в
том, чтобы поддерживать «согласованные» данные, поскольку они подчиняются
некоторым логическим проверкам. Обычно системы баз данных использовали
сериализуемые транзакции как средство обеспечения согласованности: если каждая
отдельная транзакция покидает базу данных в «согласованном» состоянии, то
сериализуемое выполнение (эквивалентное некоторому последовательному выполнению
транзакций) гарантирует, что все транзакции соблюдают «согласованное состояние
базы данных» [^57]. Протокол «Степень 3» Грея и др. описывает классическую
(строгую) «двухфазную блокировку» (2PL), которая гарантирует сериализуемое
выполнение и является основной концепцией обработки транзакций.

Однако, сериализуемость часто считается слишком дорогой для применения. Для
повышения производительности системы баз данных часто вместо этого выполняют
транзакции, используя несериализуемую изоляцию. В этой статье удержание
блокировок стоит дорого: ожидание блокировки в случае конфликта требует времени,
а в случае взаимной блокировки (deadlock) может занять вечность (или вызвать
отказ). Поэтому уже в 1973 году системы баз данных, такие как IMS и System R,
начали экспериментировать с несериализуемыми политиками. В системе управления
параллелизмом на основе блокировок эти политики реализуются путем удержания
блокировок на более короткое время. Это обеспечивает бо́льший параллелизм и может
привести к меньшему количеству взаимоблокировок и аварий, вызванных системой, а
в распределенной настройке может обеспечить бо́льшую доступность работы.

Во второй половине этой статьи Грей и авторы предоставляют элементарную
формализацию поведения политик, основанных на блокировках. Сегодня они
широко распространены; как мы обсуждаем в главе 6, несериализуемая изоляция
используется по умолчанию в большинстве коммерческих и открытых РСУБД, а
некоторые РСУБД вообще не предлагают сериализуемость. Степень 2 теперь обычно
называется изоляцией Repeatable Read, а степень 1 теперь называется изоляцией
Read Committed, в то время как степень 0 используется нечасто [^27]. В статье
также обсуждается важное понятие восстанавливаемости: политики, при которых
транзакция может быть прервана (или «отменена»), не затрагивая другие
транзакции. Все транзакции, кроме степени 0, удовлетворяют этому свойству.

Широкий спектр альтернативных механизмов управления параллелизмом последовал за
новаторской работой Грея и соавторов по сериализации на основе блокировок. По
мере изменения аппаратного обеспечения, требований к приложениям и моделей
доступа меняются и подсистемы управления параллелизмом. Тем не менее, одно
свойство контроля параллелизма остается почти неизменным: в контроле параллелизма
не существует одностороннего «лучшего» механизма. Оптимальная стратегия зависит
от рабочей нагрузки. Чтобы проиллюстрировать это, мы включили исследование
Агравала, Кэри и Ливны. Несмотря на то, что этот документ устарел, его
методология и основные выводы остаются актуальными. Это отличный пример
вдумчивой, независимой от реализации работы по анализу производительности,
которая со временем может дать ценные уроки.

Методологически, умение выполнять так называемые «приблизительные» вычисления является
ценным навыком: быстрая оценка интересующего показателя с использованием грубой
арифметики для получения ответа в пределах порядка правильного значения может
сэкономить часы или даже годы системного внедрения и анализа производительности.
Это долгая и полезная традиция в системах баз данных, от «пятиминутного правила»
[^73] до «чисел, которые должен знать каждый» [^48]. Хотя некоторые уроки,
извлеченные из этих оценок, являются временными [^69, ^66], часто выводы дают
долгосрочные уроки.

Однако для анализа сложных систем, таких как управление параллелизмом,
моделирование может быть ценным промежуточным этапом между приблизительным
тестированием и полномасштабным тестированием систем. Исследование Agrawal
является примером такого подхода: авторы используют тщательно разработанную
систему и пользовательскую модель для имитации блокировки, перезапуска и
оптимистического управления параллелизмом.

Некоторые аспекты оценки являются особенно ценными. Во-первых, почти на каждом
графике есть точка пересечения, где явных победителей нет, поскольку наиболее
эффективный механизм зависит от рабочей нагрузки и конфигурации системы. Почти
каждое исследование производительности без точки пересечения, вероятно, будет
неинтересным. Если перед нами схема «всегда побеждает», исследование должно содержать
аналитический анализ или, в идеале, доказательство того, почему это так.
Во-вторых, авторы рассматривают широкий спектр конфигураций системы; они
исследуют и обсуждают почти все параметры своей модели. В-третьих, многие
графики демонстрируют немонотонность (то есть не всегда идут вверх и вправо);
это продукт порчи и ограниченности ресурсов. Как показывают авторы,
предположение о бесконечных ресурсах приводит к совершенно разным выводам. Менее
осторожная модель, которая делала это предположение неявным, была бы гораздо
менее полезной.

Наконец, выводы исследования разумны. Основной ценой методов, основанных на
перезапуске, является «потраченная впустую» работа в случае конфликтов. Когда
ресурсов много, спекуляция имеет смысл: напрасная работа обходится дешевле, а в
случае бесконечных ресурсов она бесплатна. Однако в случае более ограниченных
ресурсов стратегии блокировки потребляют меньше ресурсов и обеспечивают более
высокую общую производительность. Опять же, нет однозначно оптимального выбора.
Тем не менее, заключительные замечания в документе оказались предсказуемыми:
вычислительные ресурсы по-прежнему ограничены, и на самом деле в настоящее время
лишь немногие коробочные системы используют методы, полностью основанные на
перезапуске. Однако, поскольку технологические соотношения - скорость диска, сети,
скорости процессора - продолжают изменяться, пересмотр этого компромисса
является полезным.


[^27]: H. Berenson, P. Bernstein, J. Gray, J. Melton, E. O’Neil, and P. O’Neil.
A critique of ANSI SQL isolation levels. In SIGMOD, 1995.

[^48]: J. Dean. Designs, lessons and advice from building large distributed
systems (keynote). In LADIS, 2009.

[^57]: K. P. Eswaran, J. N. Gray, R. A. Lorie, and I. L. Traiger. The notions of
consistency and predicate locks in a database system. Communications of the
ACM, 19(11):624–633, 1976.

[^66]: G. Graefe. The five-minute rule twenty years later, and how flash memory
changes the rules. In DaMoN, 2007.

[^69]: J. Gray and G. Graefe. The five-minute rule ten years later, and other
computer storage rules of thumb. ACM SIGMOD Record, 26(4):63–68, 1997.

[^73]: J. Gray and F. Putzolu. The 5 minute rule for trading memory for disc
accesses and the 10 byte rule for trading memory for cpu time. In SIGMOD, 1987.

[^150]: M. Stonebraker, G. Held, E. Wong, and P. Kreps. The design and
implementation of ingres. ACM Transactions on Database Systems (TODS), 1(3):
189–222, 1976.

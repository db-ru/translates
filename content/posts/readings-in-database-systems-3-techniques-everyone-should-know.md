---
title: "Readings in Database Systems 3. Методы, которые должен знать каждый"
date: 2020-07-23T10:24:43+03:00
summary: "В этой главе мы представляем первичные и почти первичные источники для
нескольких наиболее важных концепций проектирования систем баз данных:
планирование запросов, контроль параллелизма, восстановление базы данных и
распределённость. Идеи в этой главе настолько фундаментальны для современных
систем баз данных, что их содержит почти каждая зрелая БД. Три статьи в этой
главе - это, безусловно, канонические ссылки на соответствующие темы. Более того,
в отличие от предыдущей главы, эта глава фокусируется на широко применяемых
методах и алгоритмах, а не на целых системах."
categories:
- readings in database systems
- red book
- query optimization
- concurrency control
- database recovery
- distribution
---

# 3. Методы, которые должен знать каждый

> Избранные статьи:
> 
> - Patricia G. Selinger, Morton M. Astrahan, Donald D. Chamberlin, Raymond A. Lorie,
>   Thomas G. Price. Access path selection in a relational database management system.
>   SIGMOD, 1979.
> - C. Mohan, Donald J. Haderle, Bruce G. Lindsay, Hamid Pirahesh, Peter M. Schwarz.
>   ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and
>   Partial Rollbacks Using Write-Ahead Logging. ACM Transactions on Database Systems,
>   17(1), 1992, 94-162.
> - Jim Gray, Raymond A. Lorie, Gianfranco R. Putzolu, Irving L. Traiger.
>   Granularity of Locks and Degrees of Consistency in a Shared Data Base.
>   IBM, September, 1975.
> - Rakesh Agrawal, Michael J. Carey, Miron Livny. Concurrency Control
>   Performance Modeling: Alternatives and Implications. ACM Transactions on
>   Database Systems, 12(4), 1987, 609-654.
> - C. Mohan, Bruce G. Lindsay, Ron Obermarck. Transaction Management in the R\*
>   Distributed Database Management System. ACM Transactions on Database Systems,
>   11(4), 1986, 378-396

{{< param Summary >}}

## Оптимизация запросов {#query-optimization}

Оптимизация запросов важна в архитектуре реляционных баз данных, поскольку она
является основой для обеспечения возможности обработки запросов, независимой от
данных. Основополагающий документ Селинджера и др. по System R обеспечивает
практическую оптимизацию запросов, разбивая проблему на три отдельных подзадачи:
оценка стоимости, реляционные эквивалентности, определяющие пространство поиска, и
поиск на основе затрат.

Оптимизатор предоставляет оценку стоимости выполнения каждого компонента
запроса, измеряемую в терминах затрат ввода-вывода и ЦП. Для этого оптимизатор
полагается как на предварительно вычисленную статистику по содержимому каждой
таблицы (хранящейся в системном каталоге), так и на набор эвристик для
определения кардинальности (размера) результата запроса (например, на основе
вычисленной селективности предикатов). В качестве упражнения рассмотрим эти
эвристики подробно: когда они осмыслены, а когда - нет? Как они могут быть
улучшены?

Используя эти оценки затрат, оптимизатор использует алгоритм динамического
программирования для построения плана запроса. Оптимизатор определяет набор
физических операторов, которые реализуют данный логический оператор (например,
поиск кортежа с использованием полного сканирования сегмента или с индексом).
Используя этот набор, оптимизатор итеративно создает «левое-глубокое» дерево
операторов, которое, в свою очередь, использует эвристику затрат, чтобы
минимизировать общий объем предполагаемой работы, требуемой для запуска
операторов, с учетом «интересных заказов», требуемых вышестоящими потребителями.
Это позволяет избежать необходимости учитывать все возможные упорядочения
операторов, но все еще имеет экспоненциальный размер плана; как мы увидим в
главе 7, современные оптимизаторы запросов по-прежнему борются с крупными
планами (например, с множественными объединениями). Кроме того, хотя оптимизатор
Selinger и соавторов выполняет компиляцию заранее, другие ранние системы, такие как
Ingres [^150], интерпретировали план запроса фактически, по принципу: кортеж за
кортежем.

Как и почти все оптимизаторы запросов, оптимизатор Selinger и соавторов
на самом деле не «оптимален» - нет никакой гарантии, что план,
который выберет оптимизатор, будет самым быстрым или самым дешевым. Реляционный
оптимизатор ближе по духу к оптимизации кода в современных языковых компиляторах
(т.е. будет выполняться поиск с максимальными усилиями), а не математическим
процедурам оптимизации (т. е. найдет лучшее решение). Однако многие современные
реляционные движки используют базовую методологию из данной статьи, включая
использование бинарных операторов и оценку стоимости.

## Управление параллелизмом {#concurrency-control}

В нашей первой статье о транзакциях от Грея и др. представлены две классические
идеи: многоуровневая блокировка и несколько блокировочных режимов. Эта статья,
фактически, читается как две отдельных статьи.

Во-первых, в статье представлена концепция многоуровневой блокировки. Проблема
здесь проста: при наличии базы данных с иерархической структурой, как мы должны
выполнять взаимное исключение? Когда мы должны зафиксировать грубую
гранулярность (например, всю базу данных) по сравнению с более тонкой
гранулярностью (например, одна запись), и как мы можем поддерживать
одновременный доступ к различным частям иерархии одновременно? Хотя
иерархическая структура Грея и др. (cостоящая из баз данных, областей, файлов,
индексов и записей) немного отличается от современных систем баз данных, все
системы блокировки баз данных, кроме самых элементарных, сегодня адаптируют
предложения Грея и соавторов.

Во-вторых, в статье развивается концепция множественных степеней изоляции. Как
Грей и авторы напоминают нам, что цель контроля параллелизма состоит в
том, чтобы поддерживать «согласованные» данные, поскольку они подчиняются
некоторым логическим проверкам. Обычно системы баз данных использовали
сериализуемые транзакции как средство обеспечения согласованности: если каждая
отдельная транзакция покидает базу данных в «согласованном» состоянии, то
сериализуемое выполнение (эквивалентное некоторому последовательному выполнению
транзакций) гарантирует, что все транзакции соблюдают «согласованное состояние
базы данных» [^57]. Протокол «Степень 3» Грея и др. описывает классическую
(строгую) «двухфазную блокировку» (2PL), которая гарантирует сериализуемое
выполнение и является основной концепцией обработки транзакций.

Однако, сериализуемость часто считается слишком дорогой для применения. Для
повышения производительности системы баз данных часто вместо этого выполняют
транзакции, используя несериализуемую изоляцию. В этой статье удержание
блокировок стоит дорого: ожидание блокировки в случае конфликта требует времени,
а в случае взаимной блокировки (deadlock) может занять вечность (или вызвать
отказ). Поэтому уже в 1973 году системы баз данных, такие как IMS и System R,
начали экспериментировать с несериализуемыми политиками. В системе управления
параллелизмом на основе блокировок эти политики реализуются путем удержания
блокировок на более короткое время. Это обеспечивает бо́льший параллелизм и может
привести к меньшему количеству взаимоблокировок и аварий, вызванных системой, а
в распределенной настройке может обеспечить бо́льшую доступность работы.

Во второй половине этой статьи Грей и авторы предоставляют элементарную
формализацию поведения политик, основанных на блокировках. Сегодня они
широко распространены; как мы обсуждаем в главе 6, несериализуемая изоляция
используется по умолчанию в большинстве коммерческих и открытых РСУБД, а
некоторые РСУБД вообще не предлагают сериализуемость. Степень 2 теперь обычно
называется изоляцией Repeatable Read, а степень 1 теперь называется изоляцией
Read Committed, в то время как степень 0 используется нечасто [^27]. В статье
также обсуждается важное понятие восстанавливаемости: политики, при которых
транзакция может быть прервана (или «отменена»), не затрагивая другие
транзакции. Все транзакции, кроме степени 0, удовлетворяют этому свойству.

Широкий спектр альтернативных механизмов управления параллелизмом последовал за
новаторской работой Грея и соавторов по сериализации на основе блокировок. По
мере изменения аппаратного обеспечения, требований к приложениям и моделей
доступа меняются и подсистемы управления параллелизмом. Тем не менее, одно
свойство контроля параллелизма остается почти неизменным: в контроле параллелизма
не существует одностороннего «лучшего» механизма. Оптимальная стратегия зависит
от рабочей нагрузки. Чтобы проиллюстрировать это, мы включили исследование
Агравала, Кэри и Ливны. Несмотря на то, что этот документ устарел, его
методология и основные выводы остаются актуальными. Это отличный пример
вдумчивой, независимой от реализации работы по анализу производительности,
которая со временем может дать ценные уроки.

Методологически, умение выполнять так называемые «приблизительные» вычисления является
ценным навыком: быстрая оценка интересующего показателя с использованием грубой
арифметики для получения ответа в пределах порядка правильного значения может
сэкономить часы или даже годы системного внедрения и анализа производительности.
Это долгая и полезная традиция в системах баз данных, от «пятиминутного правила»
[^73] до «чисел, которые должен знать каждый» [^48]. Хотя некоторые уроки,
извлеченные из этих оценок, являются временными [^69] [^66], часто выводы дают
долгосрочные уроки.

Однако для анализа сложных систем, таких как управление параллелизмом,
моделирование может быть ценным промежуточным этапом между приблизительным
тестированием и полномасштабным тестированием систем. Исследование Agrawal
является примером такого подхода: авторы используют тщательно разработанную
систему и пользовательскую модель для имитации блокировки, перезапуска и
оптимистического управления параллелизмом.

Некоторые аспекты оценки являются особенно ценными. Во-первых, почти на каждом
графике есть точка пересечения, где явных победителей нет, поскольку наиболее
эффективный механизм зависит от рабочей нагрузки и конфигурации системы. Почти
каждое исследование производительности без точки пересечения, вероятно, будет
неинтересным. Если перед нами схема «всегда побеждает», исследование должно содержать
аналитический анализ или, в идеале, доказательство того, почему это так.
Во-вторых, авторы рассматривают широкий спектр конфигураций системы; они
исследуют и обсуждают почти все параметры своей модели. В-третьих, многие
графики демонстрируют немонотонность (то есть не всегда идут вверх и вправо);
это продукт порчи и ограниченности ресурсов. Как показывают авторы,
предположение о бесконечных ресурсах приводит к совершенно разным выводам. Менее
осторожная модель, которая делала это предположение неявным, была бы гораздо
менее полезной.

Наконец, выводы исследования разумны. Основной ценой методов, основанных на
перезапуске, является «потраченная впустую» работа в случае конфликтов. Когда
ресурсов много, спекуляция имеет смысл: напрасная работа обходится дешевле, а в
случае бесконечных ресурсов она бесплатна. Однако в случае более ограниченных
ресурсов стратегии блокировки потребляют меньше ресурсов и обеспечивают более
высокую общую производительность. Опять же, нет однозначно оптимального выбора.
Тем не менее, заключительные замечания в документе оказались предсказуемыми:
вычислительные ресурсы по-прежнему ограничены, и на самом деле в настоящее время
лишь немногие коробочные системы используют методы, полностью основанные на
перезапуске. Однако, поскольку технологические соотношения - скорость диска, сети,
скорости процессора - продолжают изменяться, пересмотр этого компромисса
является полезным.

## Восстановление Базы Данных {#database-recovery}

Другой важной проблемой в обработке транзакций является поддержание
долговечности: результаты обработки транзакций должны выдерживать сбои системы.
Широко применяемым способом поддержания долговечности является ведение
журнала: во время выполнения транзакции, операции транзакции хранятся на
отказоустойчивом носителе (например, жестких дисках или твердотельных
накопителях) в журнале. Каждый, кто работает с данными, должен понимать,
как работает журналирование с опережением записи, желательно с некоторыми
подробностями.

Канонический алгоритм для реализации "No Force, Steal" менеджера восстановления
на основе WAL - это алгоритм ARIES от IBM, который является предметом нашей
следующей статьи. (Старшие исследователи баз данных могут сказать вам, что очень
похожие идеи были изобретены в одно и то же время в таких местах, как Tandem и
Oracle.) В ARIES базе данных не нужно записывать грязные страницы на диск во
время фиксации (No Force""), и база данных может сбрасывать грязные
страницы на диск в любое время ("Steal") [^78]; эти политики обеспечивают
высокую производительность и присутствуют почти в каждом коммерческом
предложении СУБД, но, в свою очередь, усложняют базу данных. Основная идея ARIES
- выполнить восстановление после сбоя в три этапа. Во-первых, ARIES выполняет
фазу анализа, повторно просматривая журнал, чтобы определить, какие транзакции
выполнялись во время сбоя. Во-вторых, ARIES выполняет этап повтора (redo), (снова)
воспроизводя журнал и (на этот раз) выполняя эффекты любых транзакций, которые
выполнялись во время сбоя. В-третьих, ARIES выполняет этап отмены (undo),
проигрывая журнал в обратном порядке и отменяя эффект незафиксированных транзакций.
Таким образом, ключевая идея в ARIES - «повторить историю» для восстановления;
фактически, фаза отмены (undo) может выполнять ту же логику, которая используется для
прерывания транзакции во время нормальной работы.

ARIES должен быть довольно простой статьей, но, возможно, это самая сложная
статья в этом сборнике. В курсах по базам данных для аспирантов эта
статья представляет собой обряд посвящения. Однако этот материал фундаментален,
поэтому его важно понимать. К счастью, учебник Рамакришнана и Герке для
бакалавриата [^127] и обзорная статья Майкла Франклина [^61] представляют более
мягкую трактовку. Полный текст ARIES, который мы здесь включили, значительно
усложняется отвлекающими обсуждениями недостатков альтернативных проектных
решений. На первом этапе мы призываем читателей игнорировать этот материал и
сосредоточиться исключительно на подходе ARIES. Недостатки альтернатив важны, но
их следует сохранить для более внимательного второго или третьего чтения. Помимо
организации, обсуждение протоколов ARIES дополнительно усложняется обсуждениями
управления внутренним состоянием, например индексами (т.е. вложенными верхними
действиями и логическим журналированием отмены операций - последнее также
используется в экзотических схемах, таких как эскроу транзакции [^124]) и
методов, позволяющих минимизировать время простоя во время восстановления.
На практике важно, чтобы время восстановления было как можно короче; этого
сложно добиться.


## Распределённость {#distribution}

Наша последняя статья в этой главе касается выполнения транзакций в
распределенной среде. Эта тема особенно важна сегодня, поскольку все большее
количество распределенных баз данных - либо реплицированных, с несколькими
копиями данных на разных серверах, либо секционированных (партиционированных),
с элементами данных, хранящимися на отдельных серверах (или на обоих). Несмотря
на преимущества в отношении ёмкости, надёжности и доступности, распределённость
создает новый набор проблем. Серверы могут выйти из строя, а сеть может быть
ненадёжной. При отсутствии сбоев, сетевое взаимодействие может быть
дорогостоящим.

Мы концентрируемся на одном из основных методов обработки распределенных
транзакций: атомарном обязательстве (atomic commitment, AC). Очень неформально,
это означает, что для транзакции, которая выполняется на нескольких серверах
(будь то несколько реплик, несколько разделов или оба), AC гарантирует, что
транзакция либо зафиксируется, либо прервется на всех из них. Классический
алгоритм достижения AC относится к середине 1970-х годов и называется двухфазной
фиксацией (Two-Phase Commit, 2PC; не путать с 2PL выше!) [^67] [^100]. Помимо
хорошего обзора 2PC и взаимодействия между протоколом фиксации и WAL, статья
содержит два варианта AC, которые улучшают его производительность. Вариант
«Предполагаемое прерывание» (Presumed Abort) позволяет процессам избегать
принятия решения о прерывании на диск или подтверждения других прерываний, что
уменьшает использование диска и сетевого трафика. Оптимизация «Предполагаемая
фиксация» (Presumed Commit) аналогична: оптимизируется дисковое пространство и
сетевой трафик при фиксации большего количества транзакций. Обратите внимание на
сложность взаимодействия между протоколом 2PC, локальным хранилищем и локальным
диспетчером транзакций; эти детали важны, и правильная реализация этих протоколов
может быть сложной задачей.

Возможность сбоев существенно усложняет AC (и большинство проблем в
распределенных вычислениях). Например, в 2PC, что произойдет, если координатор и
участник потерпят неудачу после того, как все участники отправили свои голоса,
но до того, как координатор получит известие от отказавшего участника? Остальные
участники не будут знать, зафиксировать или прервать транзакцию: проголосовал ли
отказавший участник ДА или НЕТ? Участники не могут безопасно продолжить.
Фактически, любая реализация AC может блокировать или не работать в ненадежной
сети [^28]. В сочетании с сериализуемым механизмом управления параллелизмом
блокировка AC означает, что пропускная способность может упасть до 0.
В результате, мы имеем связанный набор AC-алгоритмов, которые исследовали AC при
смягченных предположениях, касающихся как сети (например, предполагая синхронную
сеть) [^145], так и информации, доступной серверам (например, с использованием
«детектора отказов», который определяет, когда узлы выходят из строя) [^76].

Наконец, многие читатели могут быть знакомы с тесно связанной проблемой
консенсуса или, возможно, слышали о консенсусных реализациях, таких как алгоритм
Paxos. При консенсусе может быть выбрано любое предложение, если все процессы в
конечном итоге согласятся с ним. (Напротив, в AC любой отдельный участник может
проголосовать «НЕТ», после чего все участники должны прервать работу.) Это
делает консенсус «более легкой» проблемой, чем AC [^75], но, как и AC, любая
реализация консенсуса может также блокировать определенные сценарии [^60].
В современных распределенных базах данных консенсус часто используется в
качестве основы для репликации, чтобы гарантировать, что реплики применяют
обновления в том же порядке, как экземпляр репликации на конечных автоматах (см.
туториал Шнайдера [^141]). AC часто используется для выполнения транзакций,
охватывающих несколько секций (партиций). Paxos от Лампорта [^99] - одна из самых
ранних (и наиболее известных, отчасти из-за презентации, которая конкурирует с
ARIES по сложности) реализаций консенсуса. Однако алгоритмы Viewstamped
Replication [^102] и Raft [^125], ZAB [^92] и Multi-Paxos [^35] могут оказаться
более полезными на практике. Это связано с тем, что эти алгоритмы реализуют
абстракцию распределенного журнала (distributed log) (а не «консенсусный
объект» (consensus object), как в исходной статье Paxos).

К сожалению, сообщества баз данных и распределенных вычислений несколько
разделены. Несмотря на общие интересы в реплицируемых данных, обмен идеями между
ними в течение многих лет был ограничен. В эпоху облачного и масштабируемого
управления данными этот разрыв сократился. Например, Грей и Лэмпорт в 2006 году
совместно работали над Paxos Commit [^71], интересным алгоритмом, сочетающим AC и
Paxos Лэмпорта. На этом пересечении еще многое предстоит сделать, и количество
«техник, которые каждый должен знать» в этом пространстве выросло.


[^27]: H. Berenson, P. Bernstein, J. Gray, J. Melton, E. O’Neil, and P. O’Neil.
A critique of ANSI SQL isolation levels. In SIGMOD, 1995.

[^28]: P. Bernstein, V. Hadzilacos, and N. Goodman. Concurrency control and
recovery in database systems, volume 370. Addison-Wesley New York, 1987.

[^35]: T. D. Chandra, R. Griesemer, and J. Redstone. Paxos made live: an
engineering perspective. In PODC, 2007.

[^48]: J. Dean. Designs, lessons and advice from building large distributed
systems (keynote). In LADIS, 2009.

[^57]: K. P. Eswaran, J. N. Gray, R. A. Lorie, and I. L. Traiger. The notions of
consistency and predicate locks in a database system. Communications of the
ACM, 19(11):624–633, 1976.

[^60]: M. J. Fischer, N. A. Lynch, and M. S. Paterson. Impossibility of
distributed consensus with one faulty process. Journal of the ACM (JACM),
32(2):374–382, 1985.

[^61]: M. J. Franklin. Concurrency control and recovery. The Computer Science
and Engineering Handbook, pages 1–58–1077, 1997.

[^66]: G. Graefe. The five-minute rule twenty years later, and how flash memory
changes the rules. In DaMoN, 2007.

[^67]: J. Gray. Notes on data base operating systems. In Operating Systems: An
Advanced Course, volume 60 of Lecture Notes in Computer Science, pages 393–481.
Springer Berlin Heidelberg, 1978.

[^69]: J. Gray and G. Graefe. The five-minute rule ten years later, and other
computer storage rules of thumb. ACM SIGMOD Record, 26(4):63–68, 1997.

[^71]: J. Gray and L. Lamport. Consensus on transaction commit. ACM Transactions
on Database Systems (TODS), 31(1):133–160, Mar. 2006.

[^73]: J. Gray and F. Putzolu. The 5 minute rule for trading memory for disc
accesses and the 10 byte rule for trading memory for cpu time. In SIGMOD, 1987.

[^75]: R. Guerraoui. Revisiting the relationship between non-blocking atomic
commitment and consensus. In WDAG, 1995.

[^76]: R. Guerraoui, M. Larrea, and A. Schiper. Non blocking atomic commitment
with an unreliable failure detector. In SRDS, 1995.

[^78]: T. Haerder and A. Reuter. Principles of transaction-oriented database
recovery. ACM Computing Surveys (CSUR), 15(4):287–317, 1983.

[^92]: F. P. Junqueira, B. C. Reed, and M. Serafini. Zab: High-performance
broadcast for primary-backup systems. In DSN, 2011.

[^99]: L. Lamport. The part-time parliament. ACM Transactions on Computer
Systems (TOCS), 16(2):133–169, 1998.

[^100]: B. Lampson and H. Sturgis. Crash recovery in a distributed data storage
system. Technical report, 1979.

[^102]: B. Liskov and J. Cowling. Viewstamped replication revisited. Technical
report, MIT, 2012.

[^124]: P. E. O’Neil. The escrow transactional method. ACM Transactions on
Database Systems, 11(4):405–430, 1986

[^125]: D. Ongaro and J. Ousterhout. In search of an understandable consensus
algorithm. In USENIX ATC, 2014.

[^127]: R. Ramakrishnan and J. Gehrke. Database management systems. McGraw Hill, 2000.

[^141]: F. B. Schneider. Implementing fault-tolerant services using the state
machine approach: A tutorial. ACM Computing Surveys (CSUR), 22(4):299–319, 1990.

[^145]: D. Skeen. Nonblocking commit protocols. In SIGMOD, 1981.

[^150]: M. Stonebraker, G. Held, E. Wong, and P. Kreps. The design and
implementation of ingres. ACM Transactions on Database Systems (TODS), 1(3):
189–222, 1976.
